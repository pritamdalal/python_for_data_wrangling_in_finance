{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 - Introduction to `numpy` and `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is becoming a de facto standard programming language in science and data analysis.  However, this was not always the case.  Python was initially as a general purpose programminng language, with no particular emphasis on data data analysis.\n",
    "\n",
    "Python became a scientific computing workhorse through the development of two packages: `numpy` and `pandas`.  The purpose of this tutorial is to introduce these two packages, and along the way to take a first look at some financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's start by importing the packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> import numpy as np\n",
    "##> import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these packages have a lot of functionality, but here is what they do in brief:\n",
    "\n",
    "`numpy`: vector and matrix computation (similar to what is native in R and Matlab)\n",
    "\n",
    "`pandas`: introduces `DataFrame` data structure that allows for analysis of data (like R and SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `numpy.array`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already discussed the `list` structure, which is Python's simplest and most flexible way of storing multiple values in a single variable.\n",
    "\n",
    "The of `lists` flexibility comes at a cost of performance: large `lists` are very slow.\n",
    "\n",
    "The `array` structure in the `numpy` package can be thought of as a vector or a matrix, and allows for efficient computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to create an array is by starting with a `list` and then use the `np.array()` method.  \n",
    "\n",
    "Let's try the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> l = [1, 2, 3]\n",
    "##> arr1 = np.array(l)\n",
    "##> arr2 = np.array([1, 2, 3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore the types of the variables we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> print(type(l))\n",
    "##> print(type(arr1))\n",
    "##> print(type(arr2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the content of what's inside our two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> print(arr1)\n",
    "##> print(arr2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you print an array to the console (without using `print()`), this is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> arr1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically won't work with `arrays` directly, or have to build them from scratch.\n",
    "\n",
    "Usually, we will be working with `arrays` indirectly, since `pandas` `Dataframes` are built on top of them.\n",
    "\n",
    "It's good to know `arrays` exist, and to realize that `numpy` is what makes scientific computing possible in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Create an `array` that consists of 5 zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame` structure from the `pandas` package is going to be our primary data analysis workhorse.\n",
    "\n",
    "A `DataFrame` is a convenient way to store rectangular data that consists of rows and columns.\n",
    "\n",
    "Usually, the data that goes in a `DataFrame` comes from an external source.  \n",
    "\n",
    "In this class, our data will usually come from special text files, called CSV files, and will be read into a `DataFrame` via the `pandas.read_csv()` method.  We will occassionally use built-in Python functions to query data from the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in our first data set into a `DataFrame` by typing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy = pd.read_csv('../data/spy_dec_2018.csv')\n",
    "##> df_spy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `DataFrame` consists of all the December end-of-day prices for SPY, which is an ETF that tracks the S&P500 Index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the `df_spy` `DataFrame` that we have just created.  \n",
    "\n",
    "This is a very typical thing to do once you've loaded a new dataset.\n",
    "\n",
    "First, we can first use the `type()` method to make sure what we have created is in fact a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> type(df_spy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use the `.dtypes` attribute of the `DataFrame` to see the data types of each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of rows and columns by using the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our dataframe `df_spy` consists of 18 row and 7 columns.\n",
    "\n",
    "A `DataFrame` can be thought of as a collection of rows and a collection of columns.  Both view points are useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Try the `DataFrame.info()` and `DataFrame.describe()` methods on `df_spy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataFrame` Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to isolate a particular column, say the `close` column, we can use square brackets (`[ ]`) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy['close']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "\n",
    "**Code Challenge:** Isolate the `date` column of `df_spy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the following code, each column of a `DataFrame` is actually a different kind of `pandas` structure called a `Series`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> type(df_spy['close'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a bit of `pandas` inside baseball (don't get too bogged down with these details for now):\n",
    "\n",
    "- A `pandas.DataFrame` is really a collection of columns glued together, and each column is a `pandas.Series`.\n",
    "\n",
    "- A `pandas.Series` has two major components: 1) `.values`; 2) `.index`.\n",
    "\n",
    "- The `.values` of a `Series` is a `numpy.array`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `.values` attribute of the `close` column of `df_spy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy['close'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Verify that the `values` component of the `close` column of `df_spy` is in fact a a `numpy.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component-wise Column Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the previous section, a `pandas.DataFrame` column is essentially a fancy `numpy.array`.\n",
    "\n",
    "We can think of a `numpy.array` as a vector or matrix in Python.\n",
    "\n",
    "As such, we can perform vector-like calculations with `DataFrame` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can perform scalar arithmetic on the entire column, and the calculation *broadcasts* as we would expect.  The following code divides all the `close` prices by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy['close'] / 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follow code adds 100 to all the `close` prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy['close'] + 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform component-wise calculations between two colums.\n",
    "\n",
    "Let's say we want to calculate the intraday range of SPY for each of the trade-dates in `df_spy`.  This is the difference between the `high` and the `low` of each day.  We can do this easily from the columns of our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy['high'] - df_spy['low']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Calculate the difference between the `close` and `open` columns of `df_spy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Columns to a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis often involves starting with a `DataFrame` and then adding new columns to it.  The newly added columns are often functions of the existing columns.\n",
    "\n",
    "Continuing our previouse example, let's say we want to save our intraday ranges back into `df_spy` for further analysis later.  We can do this easily with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy['intraday_range'] = df_spy['high'] - df_spy['low']\n",
    "##> df_spy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we sort of assumed that `intraday_range` exists and assign a value to it, the value we assign to it is a component-wise operation on two of the existing columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Calulations on `DataFrames`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen how to do *component-wise* calculations on the column of a `DataFrame`. A *Component-wise* calculation can be thought of as a function that takes in vectors and scalars, and returns a vector.\n",
    "\n",
    "It is often useful to perform *aggregation* calculations on `DataFrame`.  An *aggregation* can be thought of a function that takes in a vector, and returns a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can use the following code to calculate the total SPY volume during December:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_spy['volume'].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down what we did here:\n",
    "\n",
    "- First, we isolated the `volume` column of the DataFrame, which is a `Series` (a souped up `numpy.array`).\n",
    "\n",
    "- A `numpy.array` has method called `.sum()` which adds up all the components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's calculate some summary statistics on the `intraday_range` column that we added to our `DataFrame` earlier.  Notice that each of these summary statistics is just an aggregating calculation on the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> print(\"Mean: \", df_spy['intraday_range'].mean()) # average\n",
    "##> print(\"St Dev:\", df_spy['intraday_range'].std()) # standard deviation\n",
    "##> print(\"Min:\" , df_spy['intraday_range'].min()) # minimum\n",
    "##> print(\"Max:\" , df_spy['intraday_range'].max()) # maximum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Calculate the average daily volume for the trade dates in `df_spy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PDSH* - Section 3.1 - Introducing Pandas Objects\n",
    "\n",
    "*PDSH* - Section 2.1 - Understanding Data Types in Python\n",
    "\n",
    "*PDSH* - Section 2.2 - The Basics of NumPy Arrays\n",
    "\n",
    "*PDSH* - Section 2.3 - Computation on NumPy Arrays: Universal Functions\n",
    "\n",
    "*PDSH* - Section 2.4 - Aggregations: Min, Max, and Everything In Between"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
