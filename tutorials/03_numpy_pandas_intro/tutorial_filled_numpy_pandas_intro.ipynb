{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 - Introduction to `numpy` and `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is becoming a de facto standard programming language in science and data analysis.  However, this was not always the case.  Python was initially as a general purpose programminng language, with no particular emphasis on data data analysis.\n",
    "\n",
    "Python became a scientific computing workhorse through the development of two packages: `numpy` and `pandas`.  The purpose of this tutorial is to introduce these two packages, and along the way to take a first look at some financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's start by importing the packages that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these packages have a lot of functionality, but here is what they do in brief:\n",
    "\n",
    "`numpy`: vector and matrix computation (similar to what is native in R and Matlab)\n",
    "\n",
    "`pandas`: introduces `DataFrame` data structure that allows for analysis of data (like R and SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `numpy.array`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already discussed the `list` structure, which is Python's simplest and most flexible way of storing multiple values in a single variable.\n",
    "\n",
    "The of `lists` flexibility comes at a cost of performance: large `lists` are very slow.\n",
    "\n",
    "The `array` structure in the `numpy` package can be thought of as a vector or a matrix, and allows for efficient computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to create an array is by starting with a `list` and then use the `np.array()` method.  \n",
    "\n",
    "Let's try the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, 2, 3]\n",
    "arr1 = np.array(l)\n",
    "arr2 = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore the types of the variables we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(l))\n",
    "print(type(arr1))\n",
    "print(type(arr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the content of what's inside our two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you print an array to the console (without using `print()`), this is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically won't work with `arrays` directly, or have to build them from scratch.\n",
    "\n",
    "Usually, we will be working with `arrays` indirectly, since `pandas` `Dataframes` are built on top of them.\n",
    "\n",
    "It's good to know `arrays` exist, and to realize that `numpy` is what makes scientific computing possible in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Create an `array` that consists of 5 zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame` structure from the `pandas` package is going to be our primary data analysis workhorse.\n",
    "\n",
    "A `DataFrame` is a convenient way to store rectangular data that consists of rows and columns.\n",
    "\n",
    "Usually, the data that goes in a `DataFrame` comes from an external source.  \n",
    "\n",
    "In this class, our data will usually come from special text files, called CSV files, and will be read into a `DataFrame` via the `pandas.read_csv()` method.  We will occassionally use built-in Python functions to query data from the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in our first data set into a `DataFrame` by typing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>273.809998</td>\n",
       "      <td>276.279999</td>\n",
       "      <td>273.450012</td>\n",
       "      <td>275.649994</td>\n",
       "      <td>98204200</td>\n",
       "      <td>271.527222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>280.279999</td>\n",
       "      <td>280.399994</td>\n",
       "      <td>277.510010</td>\n",
       "      <td>279.299988</td>\n",
       "      <td>103176300</td>\n",
       "      <td>275.122589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>278.369995</td>\n",
       "      <td>278.850006</td>\n",
       "      <td>269.899994</td>\n",
       "      <td>270.250000</td>\n",
       "      <td>177986000</td>\n",
       "      <td>266.207977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>265.920013</td>\n",
       "      <td>269.970001</td>\n",
       "      <td>262.440002</td>\n",
       "      <td>269.839996</td>\n",
       "      <td>204185400</td>\n",
       "      <td>265.804108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>269.459991</td>\n",
       "      <td>271.220001</td>\n",
       "      <td>262.630005</td>\n",
       "      <td>263.570007</td>\n",
       "      <td>161018900</td>\n",
       "      <td>259.627899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-12-10</td>\n",
       "      <td>263.369995</td>\n",
       "      <td>265.160004</td>\n",
       "      <td>258.619995</td>\n",
       "      <td>264.070007</td>\n",
       "      <td>151445900</td>\n",
       "      <td>260.120422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>267.660004</td>\n",
       "      <td>267.869995</td>\n",
       "      <td>262.480011</td>\n",
       "      <td>264.130005</td>\n",
       "      <td>121504400</td>\n",
       "      <td>260.179504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>267.470001</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>265.369995</td>\n",
       "      <td>265.459991</td>\n",
       "      <td>97976700</td>\n",
       "      <td>261.489624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-12-13</td>\n",
       "      <td>266.519989</td>\n",
       "      <td>267.489990</td>\n",
       "      <td>264.119995</td>\n",
       "      <td>265.369995</td>\n",
       "      <td>96662700</td>\n",
       "      <td>261.400940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>262.959991</td>\n",
       "      <td>264.029999</td>\n",
       "      <td>259.850006</td>\n",
       "      <td>260.470001</td>\n",
       "      <td>116961100</td>\n",
       "      <td>256.574249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>259.399994</td>\n",
       "      <td>260.649994</td>\n",
       "      <td>253.529999</td>\n",
       "      <td>255.360001</td>\n",
       "      <td>165492300</td>\n",
       "      <td>251.540680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>257.200012</td>\n",
       "      <td>257.950012</td>\n",
       "      <td>253.279999</td>\n",
       "      <td>255.080002</td>\n",
       "      <td>134515100</td>\n",
       "      <td>251.264862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>255.169998</td>\n",
       "      <td>259.399994</td>\n",
       "      <td>249.350006</td>\n",
       "      <td>251.259995</td>\n",
       "      <td>214992800</td>\n",
       "      <td>247.501999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>249.860001</td>\n",
       "      <td>251.619995</td>\n",
       "      <td>244.649994</td>\n",
       "      <td>247.169998</td>\n",
       "      <td>252053400</td>\n",
       "      <td>243.473175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>246.740005</td>\n",
       "      <td>249.710007</td>\n",
       "      <td>239.979996</td>\n",
       "      <td>240.699997</td>\n",
       "      <td>255345600</td>\n",
       "      <td>238.484512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>239.039993</td>\n",
       "      <td>240.839996</td>\n",
       "      <td>234.270004</td>\n",
       "      <td>234.339996</td>\n",
       "      <td>147311600</td>\n",
       "      <td>232.183060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>235.970001</td>\n",
       "      <td>246.179993</td>\n",
       "      <td>233.759995</td>\n",
       "      <td>246.179993</td>\n",
       "      <td>218485400</td>\n",
       "      <td>243.914063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>242.570007</td>\n",
       "      <td>248.289993</td>\n",
       "      <td>238.960007</td>\n",
       "      <td>248.070007</td>\n",
       "      <td>186267300</td>\n",
       "      <td>245.786697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>249.580002</td>\n",
       "      <td>251.399994</td>\n",
       "      <td>246.449997</td>\n",
       "      <td>247.750000</td>\n",
       "      <td>153100200</td>\n",
       "      <td>245.469635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>249.559998</td>\n",
       "      <td>250.190002</td>\n",
       "      <td>247.470001</td>\n",
       "      <td>249.919998</td>\n",
       "      <td>144299400</td>\n",
       "      <td>247.619644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        open        high         low       close     volume  \\\n",
       "0   2018-11-30  273.809998  276.279999  273.450012  275.649994   98204200   \n",
       "1   2018-12-03  280.279999  280.399994  277.510010  279.299988  103176300   \n",
       "2   2018-12-04  278.369995  278.850006  269.899994  270.250000  177986000   \n",
       "3   2018-12-06  265.920013  269.970001  262.440002  269.839996  204185400   \n",
       "4   2018-12-07  269.459991  271.220001  262.630005  263.570007  161018900   \n",
       "5   2018-12-10  263.369995  265.160004  258.619995  264.070007  151445900   \n",
       "6   2018-12-11  267.660004  267.869995  262.480011  264.130005  121504400   \n",
       "7   2018-12-12  267.470001  269.000000  265.369995  265.459991   97976700   \n",
       "8   2018-12-13  266.519989  267.489990  264.119995  265.369995   96662700   \n",
       "9   2018-12-14  262.959991  264.029999  259.850006  260.470001  116961100   \n",
       "10  2018-12-17  259.399994  260.649994  253.529999  255.360001  165492300   \n",
       "11  2018-12-18  257.200012  257.950012  253.279999  255.080002  134515100   \n",
       "12  2018-12-19  255.169998  259.399994  249.350006  251.259995  214992800   \n",
       "13  2018-12-20  249.860001  251.619995  244.649994  247.169998  252053400   \n",
       "14  2018-12-21  246.740005  249.710007  239.979996  240.699997  255345600   \n",
       "15  2018-12-24  239.039993  240.839996  234.270004  234.339996  147311600   \n",
       "16  2018-12-26  235.970001  246.179993  233.759995  246.179993  218485400   \n",
       "17  2018-12-27  242.570007  248.289993  238.960007  248.070007  186267300   \n",
       "18  2018-12-28  249.580002  251.399994  246.449997  247.750000  153100200   \n",
       "19  2018-12-31  249.559998  250.190002  247.470001  249.919998  144299400   \n",
       "\n",
       "      adjusted  \n",
       "0   271.527222  \n",
       "1   275.122589  \n",
       "2   266.207977  \n",
       "3   265.804108  \n",
       "4   259.627899  \n",
       "5   260.120422  \n",
       "6   260.179504  \n",
       "7   261.489624  \n",
       "8   261.400940  \n",
       "9   256.574249  \n",
       "10  251.540680  \n",
       "11  251.264862  \n",
       "12  247.501999  \n",
       "13  243.473175  \n",
       "14  238.484512  \n",
       "15  232.183060  \n",
       "16  243.914063  \n",
       "17  245.786697  \n",
       "18  245.469635  \n",
       "19  247.619644  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy = pd.read_csv('../data/spy_dec_2018.csv')\n",
    "df_spy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `DataFrame` consists of all the December end-of-day prices for SPY, which is an ETF that tracks the S&P500 Index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the `df_spy` `DataFrame` that we have just created.  \n",
    "\n",
    "This is a very typical thing to do once you've loaded a new dataset.\n",
    "\n",
    "First, we can first use the `type()` method to make sure what we have created is in fact a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use the `.dtypes` attribute of the `DataFrame` to see the data types of each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         object\n",
       "open        float64\n",
       "high        float64\n",
       "low         float64\n",
       "close       float64\n",
       "volume        int64\n",
       "adjusted    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of rows and columns by using the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our dataframe `df_spy` consists of 18 row and 7 columns.\n",
    "\n",
    "A `DataFrame` can be thought of as a collection of rows and a collection of columns.  Both view points are useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Try the `DataFrame.info()` and `DataFrame.describe()` methods on `df_spy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataFrame` Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to isolate a particular column, say the `close` column, we can use square brackets (`[ ]`) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     275.649994\n",
       "1     279.299988\n",
       "2     270.250000\n",
       "3     269.839996\n",
       "4     263.570007\n",
       "5     264.070007\n",
       "6     264.130005\n",
       "7     265.459991\n",
       "8     265.369995\n",
       "9     260.470001\n",
       "10    255.360001\n",
       "11    255.080002\n",
       "12    251.259995\n",
       "13    247.169998\n",
       "14    240.699997\n",
       "15    234.339996\n",
       "16    246.179993\n",
       "17    248.070007\n",
       "18    247.750000\n",
       "19    249.919998\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "\n",
    "**Code Challenge:** Isolate the `date` column of `df_spy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the following code, each column of a `DataFrame` is actually a different kind of `pandas` structure called a `Series`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spy['close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a bit of `pandas` inside baseball (don't get too bogged down with these details for now):\n",
    "\n",
    "- A `pandas.DataFrame` is really a collection of columns glued together, and each column is a `pandas.Series`.\n",
    "\n",
    "- A `pandas.Series` has two major components: 1) `.values`; 2) `.index`.\n",
    "\n",
    "- The `.values` of a `Series` is a `numpy.array`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `.values` attribute of the `close` column of `df_spy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([275.649994, 279.299988, 270.25    , 269.839996, 263.570007,\n",
       "       264.070007, 264.130005, 265.459991, 265.369995, 260.470001,\n",
       "       255.360001, 255.080002, 251.259995, 247.169998, 240.699997,\n",
       "       234.339996, 246.179993, 248.070007, 247.75    , 249.919998])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy['close'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Verify that the `values` component of the `close` column of `df_spy` is in fact a a `numpy.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component-wise Column Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the previous section, a `pandas.DataFrame` column is essentially a fancy `numpy.array`.\n",
    "\n",
    "We can think of a `numpy.array` as a vector or matrix in Python.\n",
    "\n",
    "As such, we can perform vector-like calculations with `DataFrame` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can perform scalar arithmetic on the entire column, and the calculation *broadcasts* as we would expect.  The following code divides all the `close` prices by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2.7565\n",
       "1     2.7930\n",
       "2     2.7025\n",
       "3     2.6984\n",
       "4     2.6357\n",
       "5     2.6407\n",
       "6     2.6413\n",
       "7     2.6546\n",
       "8     2.6537\n",
       "9     2.6047\n",
       "10    2.5536\n",
       "11    2.5508\n",
       "12    2.5126\n",
       "13    2.4717\n",
       "14    2.4070\n",
       "15    2.3434\n",
       "16    2.4618\n",
       "17    2.4807\n",
       "18    2.4775\n",
       "19    2.4992\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy['close'] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follow code adds 100 to all the `close` prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     375.649994\n",
       "1     379.299988\n",
       "2     370.250000\n",
       "3     369.839996\n",
       "4     363.570007\n",
       "5     364.070007\n",
       "6     364.130005\n",
       "7     365.459991\n",
       "8     365.369995\n",
       "9     360.470001\n",
       "10    355.360001\n",
       "11    355.080002\n",
       "12    351.259995\n",
       "13    347.169998\n",
       "14    340.699997\n",
       "15    334.339996\n",
       "16    346.179993\n",
       "17    348.070007\n",
       "18    347.750000\n",
       "19    349.919998\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy['close'] + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform component-wise calculations between two colums.\n",
    "\n",
    "Let's say we want to calculate the intraday range of SPY for each of the trade-dates in `df_spy`.  This is the difference between the `high` and the `low` of each day.  We can do this easily from the columns of our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.829987\n",
       "1      2.889984\n",
       "2      8.950012\n",
       "3      7.529999\n",
       "4      8.589996\n",
       "5      6.540009\n",
       "6      5.389984\n",
       "7      3.630005\n",
       "8      3.369995\n",
       "9      4.179993\n",
       "10     7.119995\n",
       "11     4.670013\n",
       "12    10.049988\n",
       "13     6.970001\n",
       "14     9.730011\n",
       "15     6.569992\n",
       "16    12.419998\n",
       "17     9.329986\n",
       "18     4.949997\n",
       "19     2.720001\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy['high'] - df_spy['low']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Calculate the difference between the `close` and `open` columns of `df_spy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Columns to a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis often involves starting with a `DataFrame` and then adding new columns to it.  The newly added columns are often functions of the existing columns.\n",
    "\n",
    "Continuing our previouse example, let's say we want to save our intraday ranges back into `df_spy` for further analysis later.  We can do this easily with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjusted</th>\n",
       "      <th>intraday_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>273.809998</td>\n",
       "      <td>276.279999</td>\n",
       "      <td>273.450012</td>\n",
       "      <td>275.649994</td>\n",
       "      <td>98204200</td>\n",
       "      <td>271.527222</td>\n",
       "      <td>2.829987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>280.279999</td>\n",
       "      <td>280.399994</td>\n",
       "      <td>277.510010</td>\n",
       "      <td>279.299988</td>\n",
       "      <td>103176300</td>\n",
       "      <td>275.122589</td>\n",
       "      <td>2.889984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>278.369995</td>\n",
       "      <td>278.850006</td>\n",
       "      <td>269.899994</td>\n",
       "      <td>270.250000</td>\n",
       "      <td>177986000</td>\n",
       "      <td>266.207977</td>\n",
       "      <td>8.950012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>265.920013</td>\n",
       "      <td>269.970001</td>\n",
       "      <td>262.440002</td>\n",
       "      <td>269.839996</td>\n",
       "      <td>204185400</td>\n",
       "      <td>265.804108</td>\n",
       "      <td>7.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>269.459991</td>\n",
       "      <td>271.220001</td>\n",
       "      <td>262.630005</td>\n",
       "      <td>263.570007</td>\n",
       "      <td>161018900</td>\n",
       "      <td>259.627899</td>\n",
       "      <td>8.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-12-10</td>\n",
       "      <td>263.369995</td>\n",
       "      <td>265.160004</td>\n",
       "      <td>258.619995</td>\n",
       "      <td>264.070007</td>\n",
       "      <td>151445900</td>\n",
       "      <td>260.120422</td>\n",
       "      <td>6.540009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>267.660004</td>\n",
       "      <td>267.869995</td>\n",
       "      <td>262.480011</td>\n",
       "      <td>264.130005</td>\n",
       "      <td>121504400</td>\n",
       "      <td>260.179504</td>\n",
       "      <td>5.389984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>267.470001</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>265.369995</td>\n",
       "      <td>265.459991</td>\n",
       "      <td>97976700</td>\n",
       "      <td>261.489624</td>\n",
       "      <td>3.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-12-13</td>\n",
       "      <td>266.519989</td>\n",
       "      <td>267.489990</td>\n",
       "      <td>264.119995</td>\n",
       "      <td>265.369995</td>\n",
       "      <td>96662700</td>\n",
       "      <td>261.400940</td>\n",
       "      <td>3.369995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>262.959991</td>\n",
       "      <td>264.029999</td>\n",
       "      <td>259.850006</td>\n",
       "      <td>260.470001</td>\n",
       "      <td>116961100</td>\n",
       "      <td>256.574249</td>\n",
       "      <td>4.179993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>259.399994</td>\n",
       "      <td>260.649994</td>\n",
       "      <td>253.529999</td>\n",
       "      <td>255.360001</td>\n",
       "      <td>165492300</td>\n",
       "      <td>251.540680</td>\n",
       "      <td>7.119995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>257.200012</td>\n",
       "      <td>257.950012</td>\n",
       "      <td>253.279999</td>\n",
       "      <td>255.080002</td>\n",
       "      <td>134515100</td>\n",
       "      <td>251.264862</td>\n",
       "      <td>4.670013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>255.169998</td>\n",
       "      <td>259.399994</td>\n",
       "      <td>249.350006</td>\n",
       "      <td>251.259995</td>\n",
       "      <td>214992800</td>\n",
       "      <td>247.501999</td>\n",
       "      <td>10.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>249.860001</td>\n",
       "      <td>251.619995</td>\n",
       "      <td>244.649994</td>\n",
       "      <td>247.169998</td>\n",
       "      <td>252053400</td>\n",
       "      <td>243.473175</td>\n",
       "      <td>6.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>246.740005</td>\n",
       "      <td>249.710007</td>\n",
       "      <td>239.979996</td>\n",
       "      <td>240.699997</td>\n",
       "      <td>255345600</td>\n",
       "      <td>238.484512</td>\n",
       "      <td>9.730011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>239.039993</td>\n",
       "      <td>240.839996</td>\n",
       "      <td>234.270004</td>\n",
       "      <td>234.339996</td>\n",
       "      <td>147311600</td>\n",
       "      <td>232.183060</td>\n",
       "      <td>6.569992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>235.970001</td>\n",
       "      <td>246.179993</td>\n",
       "      <td>233.759995</td>\n",
       "      <td>246.179993</td>\n",
       "      <td>218485400</td>\n",
       "      <td>243.914063</td>\n",
       "      <td>12.419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>242.570007</td>\n",
       "      <td>248.289993</td>\n",
       "      <td>238.960007</td>\n",
       "      <td>248.070007</td>\n",
       "      <td>186267300</td>\n",
       "      <td>245.786697</td>\n",
       "      <td>9.329986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>249.580002</td>\n",
       "      <td>251.399994</td>\n",
       "      <td>246.449997</td>\n",
       "      <td>247.750000</td>\n",
       "      <td>153100200</td>\n",
       "      <td>245.469635</td>\n",
       "      <td>4.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>249.559998</td>\n",
       "      <td>250.190002</td>\n",
       "      <td>247.470001</td>\n",
       "      <td>249.919998</td>\n",
       "      <td>144299400</td>\n",
       "      <td>247.619644</td>\n",
       "      <td>2.720001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        open        high         low       close     volume  \\\n",
       "0   2018-11-30  273.809998  276.279999  273.450012  275.649994   98204200   \n",
       "1   2018-12-03  280.279999  280.399994  277.510010  279.299988  103176300   \n",
       "2   2018-12-04  278.369995  278.850006  269.899994  270.250000  177986000   \n",
       "3   2018-12-06  265.920013  269.970001  262.440002  269.839996  204185400   \n",
       "4   2018-12-07  269.459991  271.220001  262.630005  263.570007  161018900   \n",
       "5   2018-12-10  263.369995  265.160004  258.619995  264.070007  151445900   \n",
       "6   2018-12-11  267.660004  267.869995  262.480011  264.130005  121504400   \n",
       "7   2018-12-12  267.470001  269.000000  265.369995  265.459991   97976700   \n",
       "8   2018-12-13  266.519989  267.489990  264.119995  265.369995   96662700   \n",
       "9   2018-12-14  262.959991  264.029999  259.850006  260.470001  116961100   \n",
       "10  2018-12-17  259.399994  260.649994  253.529999  255.360001  165492300   \n",
       "11  2018-12-18  257.200012  257.950012  253.279999  255.080002  134515100   \n",
       "12  2018-12-19  255.169998  259.399994  249.350006  251.259995  214992800   \n",
       "13  2018-12-20  249.860001  251.619995  244.649994  247.169998  252053400   \n",
       "14  2018-12-21  246.740005  249.710007  239.979996  240.699997  255345600   \n",
       "15  2018-12-24  239.039993  240.839996  234.270004  234.339996  147311600   \n",
       "16  2018-12-26  235.970001  246.179993  233.759995  246.179993  218485400   \n",
       "17  2018-12-27  242.570007  248.289993  238.960007  248.070007  186267300   \n",
       "18  2018-12-28  249.580002  251.399994  246.449997  247.750000  153100200   \n",
       "19  2018-12-31  249.559998  250.190002  247.470001  249.919998  144299400   \n",
       "\n",
       "      adjusted  intraday_range  \n",
       "0   271.527222        2.829987  \n",
       "1   275.122589        2.889984  \n",
       "2   266.207977        8.950012  \n",
       "3   265.804108        7.529999  \n",
       "4   259.627899        8.589996  \n",
       "5   260.120422        6.540009  \n",
       "6   260.179504        5.389984  \n",
       "7   261.489624        3.630005  \n",
       "8   261.400940        3.369995  \n",
       "9   256.574249        4.179993  \n",
       "10  251.540680        7.119995  \n",
       "11  251.264862        4.670013  \n",
       "12  247.501999       10.049988  \n",
       "13  243.473175        6.970001  \n",
       "14  238.484512        9.730011  \n",
       "15  232.183060        6.569992  \n",
       "16  243.914063       12.419998  \n",
       "17  245.786697        9.329986  \n",
       "18  245.469635        4.949997  \n",
       "19  247.619644        2.720001  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy['intraday_range'] = df_spy['high'] - df_spy['low']\n",
    "df_spy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we sort of assumed that `intraday_range` exists and assign a value to it, the value we assign to it is a component-wise operation on two of the existing columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Calulations on `DataFrames`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen how to do *component-wise* calculations on the column of a `DataFrame`. A *Component-wise* calculation can be thought of as a function that takes in vectors and scalars, and returns a vector.\n",
    "\n",
    "It is often useful to perform *aggregation* calculations on `DataFrame`.  An *aggregation* can be thought of a function that takes in a vector, and returns a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can use the following code to calculate the total SPY volume during December:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200984700"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy['volume'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down what we did here:\n",
    "\n",
    "- First, we isolated the `volume` column of the DataFrame, which is a `Series` (a souped up `numpy.array`).\n",
    "\n",
    "- A `numpy.array` has method called `.sum()` which adds up all the components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's calculate some summary statistics on the `intraday_range` column that we added to our `DataFrame` earlier.  Notice that each of these summary statistics is just an aggregating calculation on the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  6.421497299999994\n",
      "St Dev: 2.802254726800228\n",
      "Min: 2.7200010000000248\n",
      "Max: 12.419997999999993\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean: \", df_spy['intraday_range'].mean()) # average\n",
    "print(\"St Dev:\", df_spy['intraday_range'].std()) # standard deviation\n",
    "print(\"Min:\" , df_spy['intraday_range'].min()) # minimum\n",
    "print(\"Max:\" , df_spy['intraday_range'].max()) # maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** Calculate the average daily volume for the trade dates in `df_spy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PDSH* - Section 3.1 - Introducing Pandas Objects\n",
    "\n",
    "*PDSH* - Section 2.1 - Understanding Data Types in Python\n",
    "\n",
    "*PDSH* - Section 2.2 - The Basics of NumPy Arrays\n",
    "\n",
    "*PDSH* - Section 2.3 - Computation on NumPy Arrays: Universal Functions\n",
    "\n",
    "*PDSH* - Section 2.4 - Aggregations: Min, Max, and Everything In Between"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
