{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 09 - Grouping and Aggregating - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real power of data analysis with `DataFrames` comes into focus when we start utilizing the `.groupby()` and `.agg()` methods.  \n",
    "\n",
    "This is known as *grouping* and *aggregating*.\n",
    "\n",
    "Talking about grouping in the abstract can be confusing; I think it's best to see grouping in action by doing meaningful calculations.\n",
    "\n",
    "The purpose of this tutorial is to introduce grouping and aggregation by way of following finance task: calculating monthly returns and volatilities for several assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the packages that we will need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> import numpy as np\n",
    "##> import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis we will be performing will be on the set of of December 2018 prices for `SPY`, `IWM`, `QQQ`, `DIA`.\n",
    "\n",
    "Let's read that data in from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_etf = pd.read_csv(\"../data/index_etf_dec_2018.csv\")\n",
    "##> df_etf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Challenge:** Use `DataFrame` masking to isolate all the `QQQ` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Daily Log-Returns with `groupby()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ultimate goal is to calculate monthly returns and monthly volatilities for each ETF in `df_etf`.  These quantities are both functions of daily returns.  So, our first order of business is to calculate daily returns. \n",
    "\n",
    "In a previous tutorial we calculated daily returns in a vectorized fashion.  Unfortunately, we can't use the exact same approach here because there are multiple ETFs in the data set.\n",
    "\n",
    "To overcome this challenge we will use our first application of `groupby()`.\n",
    "\n",
    "Here is the vectorized code that calculated daily log-returns for each ETF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> # sorting values to get everything in the right order\n",
    "##> df_etf.sort_values(['symbol', 'date'], inplace=True)\n",
    "##> \n",
    "##> # vectorized return calculation\n",
    "##> df_etf['ret'] = \\\n",
    "##>     df_etf['close'].groupby(df_etf['symbol']).pct_change()\n",
    "##> df_etf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** If the `group_by()` worked correctly, we should see value of `NaN` in the `log_ret` column for the first trade-date of each ETF.  Use `DataFrame` masking to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `group_by()` function actually saves us from a fair amount of hassle, as we see next.\n",
    "\n",
    "The following code calculates the daily return for each day and each symbol using a `for` loop.  It is similar to the code we used in a previous tutorial except there is some logic to deal with the fact that there are different symbols in the same data set.  For the purposes of this tutorial you can simply run the code.  If you are curious about it, I encourage you to analyze it on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_etf['ret_loop'] = np.nan\n",
    "##> for ix in range(1, df_etf.shape[0]):\n",
    "##>     \n",
    "##>     # grabbing symbols from df_etf\n",
    "##>     curr_sym = df_etf.at[ix, 'symbol']\n",
    "##>     prev_sym = df_etf.at[ix-1, 'symbol']\n",
    "##>     \n",
    "##>     # grabbling prices from df_etf\n",
    "##>     curr_px = df_etf.at[ix, 'close']\n",
    "##>     prev_px = df_etf.at[ix-1, 'close']\n",
    "##>     \n",
    "##>     # calculating return\n",
    "##>     if curr_sym == prev_sym:\n",
    "##>         df_etf.at[ix, 'ret_loop'] = (curr_px / prev_px) - 1\n",
    "##> \n",
    "##> df_etf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, both return methodologies yield the same result.  The vectorized code is far more succinct (though this isn't always a good thing).\n",
    "\n",
    "We'll now proceed to calculating monthly returns and volatility for each of the ETFs in our data set.  This amounts to first grouping by `symbol`, and then performing an aggregation calculation on `returns`.  \n",
    "\n",
    "Let's start with monthly returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Return for Each `symbol`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at our data set, we now have daily returns for each day, for each of the four ETFs.  Given a bit of time, you could probably come up with a `for` loop to iterate through the `DataFrame` and produce the monthly returns for each ETF (in fact, you could modify the returns `for` loop from the previous section to do just that).  As a one-off solution, that would be fine.  But grouping and aggregating are such ubiquitous operations, that it would be inconvenient to have write a `for`-loop every time.\n",
    "\n",
    "\n",
    "Let's begin by calculating the daily growth factor in a separate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_etf['growth_factor'] = 1 + df_etf['ret']\n",
    "##> df_etf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the monthly growth factor is the product of the daily growth factors.  Here is a way to write all that logic in a single line using `.groupby()` and `.agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_factor = \\\n",
    "##>     df_etf.groupby(['symbol'])['growth_factor'].agg([np.prod]).reset_index()\n",
    "##> df_grouped_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `pandas` isn't very sophisticated about the name that it gives to the column that stores the aggregation calculation column.  It just gave it the name `prod`, which the name of the function that was used in the aggregation calculation.  Let's make `df_grouped_factor` a bit more readable by renaming that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_factor.rename(columns={'prod': 'monthly_factor'}, inplace=True)\n",
    "##> df_grouped_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, recall that the monthly return is calculated by subtracting one from the monthly growth factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_factor['monthly_return'] = df_grouped_factor['monthly_factor'] - 1\n",
    "##> df_grouped_factor[['symbol', 'monthly_return']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Volatility for Each `symbol`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the (realized/historical) volatility for each of the ETFs.  Recall that volatility is the standard deviation of the daily returns.  If we were to do this in a brute force manner, we could use `DataFrame` masking to separate out the returns for each of the four ETFs, and then calculate four separate standard deviations.\n",
    "\n",
    "However, once again with the power of `.groupby()` and `.agg()` we can do all of this with a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_vol = \\\n",
    "##>     df_etf.groupby(['symbol'])['ret'].agg([np.std]).reset_index()\n",
    "##> \n",
    "##> df_grouped_vol\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's rename our aggregation column to something more descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_vol.rename(columns={'std':'daily_vol'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have calculated is a daily volatility, but when practitioners talk about volatility, the typically annualize it.  A daily volatility is annualized by multiplying by $\\sqrt{252}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_vol['ann_vol'] = df_grouped_vol['daily_vol'] * np.sqrt(252)\n",
    "##> df_grouped_vol\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge** Use `groupby()` and `.agg()` to calculate the average daily return for each of the ETFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Reading\n",
    "\n",
    "*PDSH* - 3.8 - Aggregation and Grouping\n",
    "\n",
    "*Python for Data Analysis (McKinney)* - Chapter 9 (pp 251-274) Data Aggregation and Grouping Operations\n",
    "\n",
    "*Options, Futures, and Other Derivatives (Hull)* - Chapter 15 (pp 325-329) The Black-Scholes-Merton Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
