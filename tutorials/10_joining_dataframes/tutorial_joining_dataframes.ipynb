{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10 - Joining `DataFrames`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data analysis you will often need to combine the data from two or more `DataFrames`.  \n",
    "\n",
    "This is known as *joining*, which is a term that is borrowed from the world of SQL.  \n",
    "\n",
    "The effect of joining is similar to the lookup functions in Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the packages we will need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> import numpy as np\n",
    "##> import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we are going to use is a list of ETFs that have weekly expiring options.  What does that mean?  Most stocks or ETFs have exchange traded options that expire every month, and at any given time the monthly expiring options go out about a year.  The most liquid underlyings have actually have options that expire every week; these weekly expiring options go out about 6-8 weeks.\n",
    "\n",
    "This is a list that is published by the CBOE and it consists of all the ETFs that have weekly options trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_weekly = pd.read_csv(\"../data/weekly_etf.csv\")\n",
    "##> df_weekly.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next data set that we are going to load is a comprehensive list of all ETFs that are trading in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_etf = pd.read_csv(\"../data/etf_list.csv\")\n",
    "##> df_etf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** Notice that `df_etf` has a `segment` column which `df_weekly` does not.  This `segment` column contains asset-class information that could be useful for categorizing the weekly ETFs.\n",
    "\n",
    "**Objective:** we want to get the `segment` column into `df_weekly`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of ways of accomplishing this in `pandas` and both of them involve the `pd.merge()` method: \n",
    "\n",
    "1. *inner-joins*\n",
    "\n",
    "2. *left/right-joins* (sometimes called *outer joins*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner-Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with many of the basic operations in data analysis, it's easiest to understand inner-joins by digging into an example.\n",
    "\n",
    "Here is the line of code that accomplishes most of the work that we want done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> pd.merge(df_weekly, df_etf, how='inner', left_on='ticker', right_on='symbol')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations on the syntax:\n",
    "\n",
    "1. The first two arguments of `pd.merge()` are the two `DataFrames` we want to join together.  The first `DataFrame` is the *left* `DataFrame` and the second on is the *right* `DataFrame`. \n",
    "\n",
    "2. The `how` argument defines the type of join.\n",
    "\n",
    "3. `left_on` is the column in the left table that will be used for matching, `right_on` is the column in the right table that will be used for matching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations on output:\n",
    "\n",
    "1. The output is basically each of the two tables smashed together, however only the rows with matching ticker/symbol are retained in the output.  All columns of both tables are included.\n",
    "\n",
    "2. `df_weekly` had 67 rows in it, and `df_etf` had 2,160 row in it.  The `DataFrame` that results from `pd.merge()` has 66 rows in it.\n",
    "\n",
    "3. Notice that both `df_weekly` and `df_etf` have a column called `name`.  In the joined dataframe, suffixes of `_x` and `_y` have been added to the column names to make them unambiguous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a little clean up of our `DataFrame` so that it's just the information that we wanted: `df_weekly` with the `segment` column added to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> # keeping only the columns that we want\n",
    "##> # assigning the joined result to a variable called df_joined  \n",
    "##> df_joined = \\\n",
    "##>     pd.merge(df_weekly, df_etf, how='inner', left_on='ticker', right_on='symbol') \\\n",
    "##>     [['ticker', 'name_x', 'segment']]\n",
    "##> \n",
    "##> # renaming the 'name' column\n",
    "##> df_joined.rename(columns={'name_x':'name'}, inplace=True)\n",
    "##> \n",
    "##> # let's look at our result\n",
    "##> df_joined.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left-Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the inner-join example from the previous section, the original list of ETFs with weekly options (`df_weekly`) had 67 rows, but the joined table with the `segment` column added only has 66 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> print(df_weekly.shape)\n",
    "##> print(df_joined.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what happened?  This means that one of the `tickers` from `df_weekly` had no matching `symbol` in `df_eft`.\n",
    "\n",
    "Inner-joins, by design, are only intended to retain rows that have matches in both tables.  This may or may not be the desired behavior you are looking for.\n",
    "\n",
    "Let's say that instead we wanted to keep *ALL* the rows in the left `DataFrame`, `df_weekly`, irrespective of whether there is a match in the right `DataFrame`.\n",
    "\n",
    "This is precisely what a *left-join* is.  The syntax is the exact same as before except for the `how` argument is set to `inner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> pd.merge(df_weekly, df_etf, how='left', left_on='ticker', right_on='symbol')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "1. Notice that ticker FTK has `NaNs` for all the columns from `df_etf`.  That's because it doesn't exist in `df_etf`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research Challenge:** Google `FTK` and figure out why it's not in `df_etf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Challenge:** Use `DataFrame` masking to grab the row of `df_joined` that consists of a non-match.  Hint: the method `pd.isna()` takes as an argument an array, it returns a `True` in for all the entries that are `NaN`, and returns `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up our result so it's exactly the information that we wanted in the first place: `df_weekly` with the `segment` column added to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> # keeping only the columns that we want\n",
    "##> # assigning the joined result to a variable called df_joined  \n",
    "##> df_joined = \\\n",
    "##>     pd.merge(df_weekly, df_etf, how='left', left_on='ticker', right_on='symbol')\\\n",
    "##>     [['ticker', 'name_x', 'segment']]\n",
    "##> \n",
    "##> # renaming the 'name' column\n",
    "##> df_joined.rename(columns={'name_x':'name'}, inplace=True)\n",
    "##> \n",
    "##> # let's look at our result\n",
    "##> df_joined.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Challenge:** create the same `df_joined` as above, but instead use a `right-join` instead of a `left-join.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Reading\n",
    "\n",
    "*PDSH* - 3.7 - Combining Datasets: Merging and Joining"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
