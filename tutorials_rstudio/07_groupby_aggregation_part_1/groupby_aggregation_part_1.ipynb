{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.groupby()` and `.agg()` - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real power of data analysis with `DataFrames` comes into focus when we start utilizing the `.groupby()` and `.agg()` methods.  \n",
    "\n",
    "This is known as *grouping* and *aggregating*.\n",
    "\n",
    "Talking about grouping in the abstract can be confusing; I think it's best to see grouping in action by doing meaningful calculations.\n",
    "\n",
    "The purpose of this tutorial is to introduce grouping and aggregation by way of the following finance task: calculating monthly returns and volatilities for several ETFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the packages that we will need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> import numpy as np\n",
    "##> import pandas as pd\n",
    "##> import pandas_datareader as pdr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading-In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis will be on the set of of July 2021 prices for `SPY`, `IWM`, `QQQ`, `DIA`.\n",
    "\n",
    "Let's readin that data with `pandas_datareader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> pd.options.display.max_rows = 25\n",
    "##> df_etf = pdr.get_data_yahoo(['SPY', 'QQQ', 'IWM', 'DIA'], start='2021-06-30', end='2021-07-31')\n",
    "##> df_etf = df_etf.round(2)\n",
    "##> df_etf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is not as tidy as we would like.  Let's use method chaining to perform a series of data munging operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_etf = \\\n",
    "##>     (\n",
    "##>     df_etf\n",
    "##>         .stack(level='Symbols') #pivot the table\n",
    "##>         .reset_index() #turn date into a column \n",
    "##>         .sort_values(by=['Symbols', 'Date']) #sort\n",
    "##>         .rename(columns={'Date':'date', 'Symbols':'symbol', 'Adj Close':'adj_close','Close':'close', \n",
    "##>                          'High':'high', 'Low':'low', 'Open':'open', 'Volume':'volume'}) #renaming columns\n",
    "##>         [['date', 'symbol','open', 'high', 'low', 'close', 'volume', 'adj_close']] #reordering columns\n",
    "##>     )\n",
    "##> df_etf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Daily Returns with `groupby()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ultimate goal is to calculate monthly returns and monthly volatilities for each ETF in `df_etf`.  These quantities are both functions of daily returns.  So, our first order of business is to calculate daily returns. \n",
    "\n",
    "In a previous tutorial we calculated daily returns in a simple vectorized fashion.  Unfortunately, we can't use the exact same approach here because there are multiple ETFs in the data set.\n",
    "\n",
    "To overcome this challenge we will use our first application of `groupby()`.\n",
    "\n",
    "Here is the `.groupby()` code that calculates daily returns for each ETF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> # sorting values to get everything in the right order\n",
    "##> df_etf.sort_values(['symbol', 'date'], inplace=True)\n",
    "##> \n",
    "##> # vectorized return calculation\n",
    "##> df_etf['ret'] = \\\n",
    "##>     df_etf['close'].groupby(df_etf['symbol']).pct_change()\n",
    "##> df_etf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge:** If the `group_by()` worked correctly, we should see a `NaN` value in the `ret` column for the first trade-date of each ETF.  Use `DataFrame.query()` to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Return for Each `symbol`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now proceed to calculate monthly returns and volatilities for each of the ETFs in our data set.  This amounts to first grouping by `symbol`, and then performing an aggregation calculation on `returns`.  \n",
    "\n",
    "Let's start with monthly returns.  As a preliminary step we'll calculate the daily growth factor in a separate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_etf['daily_factor'] = 1 + df_etf['ret']\n",
    "##> df_etf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the monthly growth factor is the product of the daily growth factors.  Here is a way to write all that logic in a single line using `.groupby()` and `.agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_factor = \\\n",
    "##>     df_etf.groupby(['symbol'])['daily_factor'].agg([np.prod]).reset_index()\n",
    "##> df_grouped_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `pandas` isn't very sophisticated about the name that it gives to the column that stores the aggregation calculation.  It just gave it the name `prod`, which the name of the function that was used in the aggregation calculation.  Let's make `df_grouped_factor` a bit more readable by renaming that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_factor.rename(columns={'prod': 'monthly_factor'}, inplace=True)\n",
    "##> df_grouped_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, recall that the monthly return is calculated by subtracting one from the monthly growth factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_factor['monthly_return'] = df_grouped_factor['monthly_factor'] - 1\n",
    "##> df_grouped_factor[['symbol', 'monthly_return']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Volatility for Each `symbol`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the (realized/historical) volatility for each of the ETFs.\n",
    "\n",
    "We once again use `.groupby()` and `.agg()` to do this all in a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_vol = \\\n",
    "##>     df_etf.groupby(['symbol'])['ret'].agg([np.std]).reset_index()\n",
    "##> \n",
    "##> df_grouped_vol\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's rename our aggregation column to something more descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_vol.rename(columns={'std':'daily_vol'}, inplace=True)\n",
    "##> df_grouped_vol\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have calculated is a daily volatility, but when practitioners talk about volatility, they typically annualize it.  A daily volatility is annualized by multiplying by $\\sqrt{252}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##> df_grouped_vol['ann_vol'] = df_grouped_vol['daily_vol'] * np.sqrt(252)\n",
    "##> df_grouped_vol\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Challenge** Use `.groupby()` and `.agg()` to calculate the average daily return for each of the ETFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Reading\n",
    "\n",
    "*PDSH* - 3.8 - Aggregation and Grouping\n",
    "\n",
    "*Python for Data Analysis (McKinney)* - Chapter 9 (pp 251-274) Data Aggregation and Grouping Operations\n",
    "\n",
    "*Options, Futures, and Other Derivatives (Hull)* - Chapter 15 (pp 325-329) The Black-Scholes-Merton Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3",
   "language": "python",
   "name": "py3.7.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
